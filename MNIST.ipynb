{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "📌 in this task, we will build multi layer perceptron (mlp) model to predict a handwritten digit number, then we will fine-tune the model to maximize its accuracy"
      ],
      "metadata": {
        "id": "kl8ueeGiMRAa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFwEW-8ClGbS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading The Dataset"
      ],
      "metadata": {
        "id": "5210EFXNpu0w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌we will use the mnist dataset in keras datasets"
      ],
      "metadata": {
        "id": "AUVYzZkB8JSm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌mnist dataset is a large collection of handwritten digits (0 to 9)"
      ],
      "metadata": {
        "id": "MarFYkVC-FNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "lps2m5Axm9pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UodI7dIpI7Y",
        "outputId": "be520589-c47d-4b60-8f42-b2bcb066aa9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RZtTRjgpNkH",
        "outputId": "df608297-49d1-4264-ae8a-3740f3941cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "BCFpckIkpOVN",
        "outputId": "bc1190cd-c636-4c2c-9422-b05ef675175e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-42ec8ca8-8fec-4df5-82e1-4468812d992c\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
              "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
              "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
              "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
              "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
              "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
              "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
              "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
              "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
              "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
              "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
              "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
              "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
              "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-42ec8ca8-8fec-4df5-82e1-4468812d992c button').onclick = (e) => {\n",
              "        document.querySelector('#id-42ec8ca8-8fec-4df5-82e1-4468812d992c').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-42ec8ca8-8fec-4df5-82e1-4468812d992c button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "I7j5ZXsgptQl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Giving The Data a New Scale Between 0 and 1"
      ],
      "metadata": {
        "id": "knWHJrJDp3UE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌this is a form of normalization, by normalizing the values:\n",
        "\n",
        "1- we improve model performance\n",
        "\n",
        "2- we give a common range for all features\n"
      ],
      "metadata": {
        "id": "ygZjCXRy8THG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "WF88cQbWpRXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 80\n",
        "\n",
        "plt.imshow(X_train[index], cmap=plt.cm.binary)\n",
        "print(y_train[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "7Uh9aFj0pond",
        "outputId": "5e07cc1b-0b82-4c16-e9e3-33591a018b36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Flattening the dataset so it is in the shape that the model expects"
      ],
      "metadata": {
        "id": "j3Fj9evlqt1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_flat = X_train.reshape(len(X_train), (28 * 28))\n",
        "X_test_flat = X_test.reshape(len(X_test), (28 * 28))"
      ],
      "metadata": {
        "id": "6PqEelXXqJat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_flat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LymBPgd2rGww",
        "outputId": "fac20f96-fbbc-4ec7-8d56-c79073abb057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_flat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NArMdnWrJS8",
        "outputId": "8710a171-a503-4525-d9b2-d74c0655aad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 784)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌notice that after flattening the data, the shape of each picture of a digit will be a 1D array of 784 pixel values instead of 28*28"
      ],
      "metadata": {
        "id": "vkKspuCv9JUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building The Model (Multi Layer Perceptron)"
      ],
      "metadata": {
        "id": "pZDJd0prrk-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, input_shape=(784,), activation='relu'),\n",
        "    keras.layers.Dense(64, activation='sigmoid'),\n",
        "    keras.layers.Dense(32, activation='sigmoid'),\n",
        "    keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X_train_flat, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlgsHVJyrkRk",
        "outputId": "b1b26e76-bec2-4b98-9061-11a14c8290fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 6ms/step - accuracy: 0.7892 - loss: 0.9120\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.9618 - loss: 0.1420\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9745 - loss: 0.0907\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.9836 - loss: 0.0580\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0440\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1b0922bb20>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_flat, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8TGY9-jsSLT",
        "outputId": "12b146c0-59b5-41e6-fd93-7e5912932f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9720 - loss: 0.0975\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.08384686708450317, 0.9753999710083008]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌the model achieved a really good accuracy, with 98.7% on the training data and 97.5% on the testing data, lets see if we can increase this accuracy using hyperparameter tuning"
      ],
      "metadata": {
        "id": "26I0mdWk9uVq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameters Fine-Tuning"
      ],
      "metadata": {
        "id": "0TeC_opzuMXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌we will use keras tuner for tuning hyperparameters"
      ],
      "metadata": {
        "id": "ejfSpjOcxRkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner==1.4.7"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWK1wpaKy0EH",
        "outputId": "e9dc4d1f-fb58-4361-f519-cf7da9faa865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-tuner==1.4.7 in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner==1.4.7) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner==1.4.7) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner==1.4.7) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner==1.4.7) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner==1.4.7) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner==1.4.7) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner==1.4.7) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner==1.4.7) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner==1.4.7) (3.11.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner==1.4.7) (0.12.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner==1.4.7) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner==1.4.7) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner==1.4.7) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner==1.4.7) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner==1.4.7) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner==1.4.7) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner==1.4.7) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner==1.4.7) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner==1.4.7) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "\n",
        "def model_builder(hp):\n",
        "  model =  keras.Sequential([\n",
        "    keras.layers.Dense(units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
        "                        input_shape=(784,), activation='relu'),\n",
        "    keras.layers.Dense(64, activation='sigmoid'),\n",
        "    keras.layers.Dense(32, activation='sigmoid'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "tuner = kt.RandomSearch(model_builder,\n",
        "                        objective='val_accuracy',\n",
        "                        max_trials=5)\n",
        "\n",
        "tuner.search(X_train_flat, y_train, epochs=5, validation_data=(X_test_flat, y_test))\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "model.fit(X_train_flat, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4HM8sx5tJxI",
        "outputId": "47c38c82-f150-4f90-d654-4e43f76e0623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 01m 37s]\n",
            "val_accuracy: 0.9796000123023987\n",
            "\n",
            "Best val_accuracy So Far: 0.98089998960495\n",
            "Total elapsed time: 00h 06m 31s\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8184 - loss: 0.8428\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 7ms/step - accuracy: 0.9684 - loss: 0.1181\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9818 - loss: 0.0687\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.9880 - loss: 0.0434\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 7ms/step - accuracy: 0.9915 - loss: 0.0297\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1ae9485f00>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "📌as we can see, the validation accuracy for the model increased after hyperparameter tuning, to reach 98%"
      ],
      "metadata": {
        "id": "B80WTMbh75Yz"
      }
    }
  ]
}